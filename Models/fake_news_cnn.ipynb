{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmUcDEv25L5W"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LiyaZBkdqil",
        "outputId": "f2c3c792-793f-41da-f1dd-a49bf55427c5"
      },
      "outputs": [],
      "source": [
        "# Use this to install libraries if you find them missing on your system:\n",
        "#!pip install bs4\n",
        "#!pip install sklearn\n",
        "#!pip install nltk\n",
        "#!pip install gensim\n",
        "#!pip install lxml\n",
        "#!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uT92due2dsqS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, Flatten, Dropout, Concatenate\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "import gensim\n",
        "import gensim.downloader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSdZSs0adFur",
        "outputId": "567790be-fc04-4c95-bb92-6843c446c77a"
      },
      "outputs": [],
      "source": [
        "word2vec = gensim.downloader.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sjJ43bOZnXpr"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 300\n",
        "MAX_VOCAB_SIZE = 262144\n",
        "MAX_SEQUENCE_LENGTH = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oKXJ0FNztvGv"
      },
      "outputs": [],
      "source": [
        "# Adapted from Yoon Kim model\n",
        "# Kim, Y. (2014). Convolutional neural networks for sentence classification. https://doi.org/10.48550/arXiv.1408.5882\n",
        "\n",
        "def ConvNet(embeddings, max_sequence_length, num_words, embedding_dim, labels_index, trainable=False, extra_conv=True):\n",
        "\n",
        "    embedding_layer = Embedding(num_words,\n",
        "                            embedding_dim,\n",
        "                            weights=[embeddings],\n",
        "                            input_length=max_sequence_length,\n",
        "                            trainable=trainable)\n",
        "\n",
        "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "    convs = []\n",
        "    filter_sizes = [3,4,5]\n",
        "\n",
        "    for filter_size in filter_sizes:\n",
        "        l_conv = Conv1D(filters=128, kernel_size=filter_size, activation='relu')(embedded_sequences)\n",
        "        l_pool = MaxPooling1D(pool_size=3)(l_conv)\n",
        "        convs.append(l_pool)\n",
        "\n",
        "    l_merge = Concatenate(axis=-1)(convs)\n",
        "\n",
        "    conv = Conv1D(filters=128, kernel_size=3, activation='relu')(embedded_sequences)\n",
        "    pool = MaxPooling1D(pool_size=3)(conv)\n",
        "\n",
        "    if extra_conv==True:\n",
        "        x = Dropout(0.5)(l_merge)\n",
        "    else:\n",
        "        x = Dropout(0.5)(pool)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    preds = Dense(labels_index, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(sequence_input, preds)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKQEZZarH3I2"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a7JyWccIdsyq"
      },
      "outputs": [],
      "source": [
        "df_fake_1 = pd.DataFrame(pd.read_pickle(\"fake_news_data/clean/fake.pkl\"))\n",
        "df_real_1 = pd.DataFrame(pd.read_pickle(\"fake_news_data/clean/real.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7ffNG_xBnrM3"
      },
      "outputs": [],
      "source": [
        "df_fake_1.columns = [\"text\"]\n",
        "df_real_1.columns = [\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tm-iY2Umg6EY"
      },
      "outputs": [],
      "source": [
        "df_real_1[\"label\"] = True\n",
        "df_fake_1[\"label\"] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FYvMiRhDds48",
        "outputId": "18bc791c-218d-4792-a3eb-9669f44c39b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8953</th>\n",
              "      <td>Airline unions have called for an end to the o...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408</th>\n",
              "      <td>at Low cholesterol and its consequence we have...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11392</th>\n",
              "      <td>He finds their reluctance to speak to this mat...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9361</th>\n",
              "      <td>S Given the strength of new experts said it wa...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7248</th>\n",
              "      <td>originally It looks like everyone is releasing...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8715</th>\n",
              "      <td>Knew position long ago</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11144</th>\n",
              "      <td>had many vocal celebrities on her side during ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5125</th>\n",
              "      <td>whose world chances arrived like buses but end...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Mandatory vaccinations are about to open up a ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7417</th>\n",
              "      <td>Are you a sinister filthy Take this quiz and f...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21990 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "8953   Airline unions have called for an end to the o...   True\n",
              "5408   at Low cholesterol and its consequence we have...  False\n",
              "11392  He finds their reluctance to speak to this mat...  False\n",
              "9361   S Given the strength of new experts said it wa...  False\n",
              "7248   originally It looks like everyone is releasing...  False\n",
              "...                                                  ...    ...\n",
              "8715                              Knew position long ago  False\n",
              "11144  had many vocal celebrities on her side during ...  False\n",
              "5125   whose world chances arrived like buses but end...   True\n",
              "6      Mandatory vaccinations are about to open up a ...  False\n",
              "7417   Are you a sinister filthy Take this quiz and f...   True\n",
              "\n",
              "[21990 rows x 2 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_1 = pd.concat([df_real_1,df_fake_1])\n",
        "df_1 = df_1.sample(frac = 1)\n",
        "df_1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3kskuBZGpXnR"
      },
      "outputs": [],
      "source": [
        "X1 = df_1['text']\n",
        "y1 = df_1['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3)\n",
        "X1_train, X1_test, y1_train, y1_test = X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMpfzwF4sv5K",
        "outputId": "2e343847-a7c0-43a1-8e8e-a743446c96c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedding dim: (52007, 300)\n"
          ]
        }
      ],
      "source": [
        "tokenizer1 = Tokenizer(num_words=MAX_VOCAB_SIZE,\n",
        "                      lower=True,\n",
        "                      char_level=False,\n",
        "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                      split=' ')\n",
        "\n",
        "tokenizer1.fit_on_texts(X1_train.tolist())\n",
        "\n",
        "train_word_index_1 = tokenizer1.word_index\n",
        "train_embedding_weights_1 = np.zeros((len(train_word_index_1)+1, EMBEDDING_DIM))\n",
        "\n",
        "for word, index in train_word_index_1.items():\n",
        "    if word in word2vec:\n",
        "        train_embedding_weights_1[index,:] = word2vec[word]\n",
        "    else:\n",
        "        train_embedding_weights_1[index,:] = np.random.rand(EMBEDDING_DIM)\n",
        "\n",
        "print(\"embedding dim:\", train_embedding_weights_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_mKxhNuXteKv"
      },
      "outputs": [],
      "source": [
        "training_sequences_1 = tokenizer1.texts_to_sequences(X1_train.tolist())\n",
        "train_cnn_data_1 = pad_sequences(training_sequences_1, maxlen=MAX_SEQUENCE_LENGTH-1)\n",
        "\n",
        "test_sequences_1 = tokenizer1.texts_to_sequences(X1_test.tolist())\n",
        "test_cnn_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7met_WVs65ca"
      },
      "outputs": [],
      "source": [
        "batch_size_1 = 256\n",
        "labels_1 = 1\n",
        "num_epochs_1 = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X3hpXs3ukzQ",
        "outputId": "ee7a1ade-0080-412b-acbe-1905426a7848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 199)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 199, 300)             1560210   ['input_1[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 197, 128)             115328    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 196, 128)             153728    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 195, 128)             192128    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 65, 128)              0         ['conv1d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPoolin  (None, 65, 128)              0         ['conv1d_1[0][0]']            \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPoolin  (None, 65, 128)              0         ['conv1d_2[0][0]']            \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 65, 384)              0         ['max_pooling1d[0][0]',       \n",
            "                                                                     'max_pooling1d_1[0][0]',     \n",
            "                                                                     'max_pooling1d_2[0][0]']     \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 65, 384)              0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 24960)                0         ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  3195008   ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    129       ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19258421 (73.47 MB)\n",
            "Trainable params: 3656321 (13.95 MB)\n",
            "Non-trainable params: 15602100 (59.52 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1 = ConvNet(train_embedding_weights_1, MAX_SEQUENCE_LENGTH-1, len(train_word_index_1)+1, EMBEDDING_DIM, labels_1, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NI1ZtG8Mwf_u"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQHMXftHvFe4",
        "outputId": "64067382-b73c-4b80-9bc6-b499834371b8"
      },
      "outputs": [],
      "source": [
        "hist = model1.fit(train_cnn_data_1, y1_train, epochs=num_epochs_1, validation_split=0.1, shuffle=True, batch_size=batch_size_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST_1Ia3pw6dy",
        "outputId": "9795ca4c-241f-42a2-8ffb-a98614e38da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 9s 1s/step\n"
          ]
        }
      ],
      "source": [
        "y1_predicted = model1.predict(test_cnn_data_1, batch_size=1024, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dPWFCUhWw-q9"
      },
      "outputs": [],
      "source": [
        "y1_pred = np.round(y1_predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJLLEn3_0nkJ",
        "outputId": "a843ccc2-171c-4f49-a762-facffc29fb38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8737304835531302"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y1_test, y1_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Df0g7l5UM9"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R7hFB_ci5XfZ"
      },
      "outputs": [],
      "source": [
        "df_fake_2 = pd.DataFrame(pd.read_csv(\"fake.csv\"))\n",
        "df_fake_2 = df_fake_2.drop([\"title\", \"uuid\", \"ord_in_thread\", \"author\", \"published\", \"language\", \"crawled\", \"site_url\",\t\"country\"\t,\"domain_rank\"\t,\"thread_title\",\t\"spam_score\",\t\"main_img_url\",\t\"replies_count\", \"participants_count\", \"likes\", \"comments\", \"shares\"], axis = 1)\n",
        "df_fake_2[\"text\"] = df_fake_2[\"text\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XlnKC2rnFYmE"
      },
      "outputs": [],
      "source": [
        "df_fake_2 = df_fake_2.join(pd.get_dummies(df_fake_2['type']))\n",
        "df_fake_2 = df_fake_2.drop('type', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "i63SMlRiP4Gw",
        "outputId": "e186a145-6d96-4864-f3ac-47db7e870924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows with label 'bs': 11492 \n",
            "Number of rows with other labels: 1507\n"
          ]
        }
      ],
      "source": [
        "df_fake_bs = df_fake_2[df_fake_2.bs == True]\n",
        "df_fake_notbs = df_fake_2[df_fake_2.bs != True]\n",
        "print(\"Number of rows with label 'bs':\", len(df_fake_bs),\"\\nNumber of rows with other labels:\", len(df_fake_notbs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>bias</th>\n",
              "      <th>bs</th>\n",
              "      <th>conspiracy</th>\n",
              "      <th>fake</th>\n",
              "      <th>hate</th>\n",
              "      <th>junksci</th>\n",
              "      <th>satire</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6459</th>\n",
              "      <td>Keywords: beauty , blackheads , blackheads tre...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4933</th>\n",
              "      <td>Wikileaks Email: Clinton Operative Thinks â€œBla...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7269</th>\n",
              "      <td>By Sean Colarossi on Mon, Oct 31st, 2016 at 8:...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>By Nadia Prupis Canadian free speech advocates...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673</th>\n",
              "      <td>Juror explanation for Ammon Bundy verdict 11/0...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2342</th>\n",
              "      <td>Dr. David Duke and Prof. Kevin MacDonald on Du...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1614</th>\n",
              "      <td>Email \\nIf his campaign is any indication, Don...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>By Catherine J. Frompovich This is the continu...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2237</th>\n",
              "      <td>Christie Lost Republicans The 2012 Election. H...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7649</th>\n",
              "      <td>Democrats Loved Jonathan Gruber Before They Fo...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2082 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text   bias     bs  \\\n",
              "6459  Keywords: beauty , blackheads , blackheads tre...  False  False   \n",
              "4933  Wikileaks Email: Clinton Operative Thinks â€œBla...  False  False   \n",
              "7269  By Sean Colarossi on Mon, Oct 31st, 2016 at 8:...   True  False   \n",
              "300   By Nadia Prupis Canadian free speech advocates...  False  False   \n",
              "673   Juror explanation for Ammon Bundy verdict 11/0...  False   True   \n",
              "...                                                 ...    ...    ...   \n",
              "2342  Dr. David Duke and Prof. Kevin MacDonald on Du...  False  False   \n",
              "1614  Email \\nIf his campaign is any indication, Don...  False  False   \n",
              "321   By Catherine J. Frompovich This is the continu...  False  False   \n",
              "2237  Christie Lost Republicans The 2012 Election. H...   True  False   \n",
              "7649  Democrats Loved Jonathan Gruber Before They Fo...  False  False   \n",
              "\n",
              "      conspiracy   fake   hate  junksci  satire  state  \n",
              "6459       False  False  False     True   False  False  \n",
              "4933        True  False  False    False   False  False  \n",
              "7269       False  False  False    False   False  False  \n",
              "300         True  False  False    False   False  False  \n",
              "673        False  False  False    False   False  False  \n",
              "...          ...    ...    ...      ...     ...    ...  \n",
              "2342       False  False   True    False   False  False  \n",
              "1614       False  False  False    False    True  False  \n",
              "321         True  False  False    False   False  False  \n",
              "2237       False  False  False    False   False  False  \n",
              "7649        True  False  False    False   False  False  \n",
              "\n",
              "[2082 rows x 9 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_fake_bs_sample = df_fake_bs.sample(frac= 0.05)\n",
        "df_fake_new = pd.concat([df_fake_bs_sample, df_fake_notbs])\n",
        "df_fake_new = df_fake_new.sample(frac=1)\n",
        "df_fake_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "io3SddrJHEie"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(df_fake_new, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6OqO00XZR_1s"
      },
      "outputs": [],
      "source": [
        "X2_train = train[\"text\"]\n",
        "X2_test = test[\"text\"]\n",
        "\n",
        "label_names = [\"bias\", \"bs\", \"conspiracy\", \"fake\", \"hate\", \"junksci\", \"satire\", \"state\"]\n",
        "y2_train = train[label_names].values\n",
        "y2_test = test[label_names].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px_O9VdkJKAS",
        "outputId": "97a6711a-4083-48e6-d2c5-16e63aff03c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedding dim: (44410, 300)\n"
          ]
        }
      ],
      "source": [
        "tokenizer2 = Tokenizer(num_words=MAX_VOCAB_SIZE,\n",
        "                      lower=True,\n",
        "                      char_level=False,\n",
        "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                      split=' ')\n",
        "\n",
        "tokenizer2.fit_on_texts(X2_train.tolist())\n",
        "\n",
        "train_word_index_2 = tokenizer2.word_index\n",
        "train_embedding_weights_2 = np.zeros((len(train_word_index_2)+1, EMBEDDING_DIM))\n",
        "\n",
        "for word,index in train_word_index_2.items():\n",
        "    if word in word2vec:\n",
        "        train_embedding_weights_2[index,:] = word2vec[word]\n",
        "    else:\n",
        "        train_embedding_weights_2[index,:] = np.random.rand(EMBEDDING_DIM)\n",
        "\n",
        "print(\"embedding dim:\", train_embedding_weights_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3JIzO_jDJ7oA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1665\n"
          ]
        }
      ],
      "source": [
        "training_sequences_2 = tokenizer2.texts_to_sequences(X2_train.tolist())\n",
        "train_cnn_data_2 = pad_sequences(training_sequences_2, maxlen=MAX_SEQUENCE_LENGTH-1)\n",
        "\n",
        "test_sequences_2 = tokenizer2.texts_to_sequences(X2_test.tolist())\n",
        "test_cnn_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH-1)\n",
        "\n",
        "print(len(train_cnn_data_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9VI8UY6RJ_vt"
      },
      "outputs": [],
      "source": [
        "batch_size_2 = 256\n",
        "labels_2 = 8\n",
        "num_epochs_2 = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foe6rPSYKGVw",
        "outputId": "e9e0e13a-f17d-44bb-a0c1-f02a86861d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 199)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 199, 300)             1332300   ['input_2[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 197, 128)             115328    ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 196, 128)             153728    ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 195, 128)             192128    ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPoolin  (None, 65, 128)              0         ['conv1d_4[0][0]']            \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPoolin  (None, 65, 128)              0         ['conv1d_5[0][0]']            \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling1d_6 (MaxPoolin  (None, 65, 128)              0         ['conv1d_6[0][0]']            \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 65, 384)              0         ['max_pooling1d_4[0][0]',     \n",
            " )                                                                   'max_pooling1d_5[0][0]',     \n",
            "                                                                     'max_pooling1d_6[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 65, 384)              0         ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 24960)                0         ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 128)                  3195008   ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 128)                  0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 8)                    1032      ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16980224 (64.77 MB)\n",
            "Trainable params: 3657224 (13.95 MB)\n",
            "Non-trainable params: 13323000 (50.82 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2 = ConvNet(train_embedding_weights_2, MAX_SEQUENCE_LENGTH-1, len(train_word_index_2)+1, EMBEDDING_DIM, labels_2, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "BlUIWg34KKCk"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKpPY__BREWE",
        "outputId": "ff9aec45-8c8e-4c51-dba6-37e9bc626c46"
      },
      "outputs": [],
      "source": [
        "hist = model2.fit(train_cnn_data_2, y2_train, epochs=num_epochs_2, validation_split=0.1, shuffle=True, batch_size=batch_size_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhkU1Rt2SlC3",
        "outputId": "44745389-7e3c-499a-c121-b306fab30579"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 802ms/step\n"
          ]
        }
      ],
      "source": [
        "y2_predicted = model2.predict(test_cnn_data_2, batch_size=1024, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Il8542xLTdy1"
      },
      "outputs": [],
      "source": [
        "df2_pred = pd.DataFrame(y2_predicted)\n",
        "df2_pred = df2_pred.where(df2_pred!=0).rank(1, ascending=False, method='dense').eq(1).astype(int)\n",
        "np2_pred = df2_pred.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddixyUpETw16",
        "outputId": "67f1e7d4-d5e6-4ac3-f507-d81d42d37be0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5371702637889688"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y2_test, np2_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0  1  2  3  4  5  6  7\n",
              "317  0  1  0  0  0  0  0  0\n",
              "137  0  0  1  0  0  0  0  0\n",
              "261  0  1  0  0  0  0  0  0\n",
              "139  1  0  0  0  0  0  0  0\n",
              "181  0  0  1  0  0  0  0  0\n",
              "385  0  1  0  0  0  0  0  0\n",
              "283  1  0  0  0  0  0  0  0\n",
              "119  0  1  0  0  0  0  0  0\n",
              "188  0  1  0  0  0  0  0  0\n",
              "31   0  0  0  0  0  0  0  1\n",
              "11   0  0  0  0  1  0  0  0\n",
              "378  0  1  0  0  0  0  0  0\n",
              "27   1  0  0  0  0  0  0  0\n",
              "246  0  1  0  0  0  0  0  0\n",
              "166  0  1  0  0  0  0  0  0\n",
              "398  1  0  0  0  0  0  0  0\n",
              "231  0  1  0  0  0  0  0  0\n",
              "335  0  1  0  0  0  0  0  0\n",
              "341  1  0  0  0  0  0  0  0\n",
              "203  0  1  0  0  0  0  0  0\n",
              "135  0  1  0  0  0  0  0  0\n",
              "123  0  1  0  0  0  0  0  0\n",
              "202  0  1  0  0  0  0  0  0\n",
              "288  0  0  1  0  0  0  0  0\n",
              "265  0  1  0  0  0  0  0  0\n",
              "321  0  0  1  0  0  0  0  0\n",
              "258  0  1  0  0  0  0  0  0\n",
              "40   0  1  0  0  0  0  0  0\n",
              "368  0  1  0  0  0  0  0  0\n",
              "86   0  1  0  0  0  0  0  0\n",
              "328  0  1  0  0  0  0  0  0\n",
              "349  1  0  0  0  0  0  0  0\n",
              "111  1  0  0  0  0  0  0  0\n",
              "93   0  1  0  0  0  0  0  0\n",
              "87   0  0  1  0  0  0  0  0\n",
              "192  1  0  0  0  0  0  0  0\n",
              "105  0  0  0  0  0  0  0  1\n",
              "402  0  0  1  0  0  0  0  0\n",
              "228  0  1  0  0  0  0  0  0\n",
              "65   0  0  1  0  0  0  0  0\n",
              "386  0  0  0  0  1  0  0  0\n",
              "355  0  1  0  0  0  0  0  0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(np2_pred).sample(frac= 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Check Models Compatibility\n",
        "(using the model from Part 2 on the fake news obtained from Part 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3407</th>\n",
              "      <td>Did you In some individuals born with the cong...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3747</th>\n",
              "      <td>The ministration Management System has started...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4887</th>\n",
              "      <td>if he solves all his cases in minutes or has d...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3292</th>\n",
              "      <td>J Trump made coal a centerpiece of his holding...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3788</th>\n",
              "      <td>Former National Guardsman turned State sympath...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3096</th>\n",
              "      <td>is AND fucked Time to airlift in cases of</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2836</th>\n",
              "      <td>Will in</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6553</th>\n",
              "      <td>die oder hat die um um die die Die die die Lan...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3635</th>\n",
              "      <td>has asserted that democracy can only be upheld...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4114</th>\n",
              "      <td>With protests erupting across the country this...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>382 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "3407  Did you In some individuals born with the cong...    0.0\n",
              "3747  The ministration Management System has started...    0.0\n",
              "4887  if he solves all his cases in minutes or has d...    0.0\n",
              "3292  J Trump made coal a centerpiece of his holding...    0.0\n",
              "3788  Former National Guardsman turned State sympath...    0.0\n",
              "...                                                 ...    ...\n",
              "3096          is AND fucked Time to airlift in cases of    0.0\n",
              "2836                                            Will in    0.0\n",
              "6553  die oder hat die um um die die Die die die Lan...    0.0\n",
              "3635  has asserted that democracy can only be upheld...    0.0\n",
              "4114  With protests erupting across the country this...    0.0\n",
              "\n",
              "[382 rows x 2 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_combine = pd.DataFrame(X1_test)\n",
        "df_combine[\"label\"] = y1_pred\n",
        "df_combine = df_combine.reset_index(drop=True)\n",
        "\n",
        "df_combine_fake = df_combine.loc[df_combine['label'] == 0.0]\n",
        "\n",
        "df_sample_fake = df_combine_fake.sample(frac=0.1)\n",
        "df_sample_fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_sample_tokenised = tokenizer2.texts_to_sequences(df_sample_fake[\"text\"].tolist())\n",
        "combined_sample_train_data = pad_sequences(combined_sample_tokenised, maxlen=MAX_SEQUENCE_LENGTH-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 615ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bias</th>\n",
              "      <th>bs</th>\n",
              "      <th>conspiracy</th>\n",
              "      <th>fake</th>\n",
              "      <th>hate</th>\n",
              "      <th>junksci</th>\n",
              "      <th>satire</th>\n",
              "      <th>state</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Did you In some individuals born with the cong...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The ministration Management System has started...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>if he solves all his cases in minutes or has d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>J Trump made coal a centerpiece of his holding...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Former National Guardsman turned State sympath...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>is AND fucked Time to airlift in cases of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Will in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>die oder hat die um um die die Die die die Lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>has asserted that democracy can only be upheld...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>With protests erupting across the country this...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>382 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     bias  bs  conspiracy  fake  hate  junksci  satire  state  \\\n",
              "0       1   0           0     0     0        0       0      0   \n",
              "1       0   1           0     0     0        0       0      0   \n",
              "2       1   0           0     0     0        0       0      0   \n",
              "3       0   1           0     0     0        0       0      0   \n",
              "4       1   0           0     0     0        0       0      0   \n",
              "..    ...  ..         ...   ...   ...      ...     ...    ...   \n",
              "377     1   0           0     0     0        0       0      0   \n",
              "378     1   0           0     0     0        0       0      0   \n",
              "379     0   0           0     0     1        0       0      0   \n",
              "380     0   1           0     0     0        0       0      0   \n",
              "381     0   1           0     0     0        0       0      0   \n",
              "\n",
              "                                                  text  \n",
              "0    Did you In some individuals born with the cong...  \n",
              "1    The ministration Management System has started...  \n",
              "2    if he solves all his cases in minutes or has d...  \n",
              "3    J Trump made coal a centerpiece of his holding...  \n",
              "4    Former National Guardsman turned State sympath...  \n",
              "..                                                 ...  \n",
              "377          is AND fucked Time to airlift in cases of  \n",
              "378                                            Will in  \n",
              "379  die oder hat die um um die die Die die die Lan...  \n",
              "380  has asserted that democracy can only be upheld...  \n",
              "381  With protests erupting across the country this...  \n",
              "\n",
              "[382 rows x 9 columns]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_predicted = model2.predict(combined_sample_train_data, batch_size=1024, verbose=1)\n",
        "\n",
        "df_combined_pred = pd.DataFrame(combined_predicted)\n",
        "df_combined_pred = df_combined_pred.where(df_combined_pred!=0).rank(1, ascending=False, method='dense').eq(1).astype(int)\n",
        "\n",
        "df_combined_pred.columns = label_names \n",
        "df_combined_pred[\"text\"] = df_sample_fake[\"text\"].values\n",
        "df_combined_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test both models on input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_news = input(\"Insert News\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_tokenised_1 = tokenizer1.texts_to_sequences([[text_news]])\n",
        "text_tokenised_1_data = pad_sequences(text_tokenised_1, maxlen=MAX_SEQUENCE_LENGTH-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_1_predicted = model1.predict(text_tokenised_1_data, batch_size=1024, verbose=1)\n",
        "text_1_predicted = np.round(np.array(text_1_predicted))\n",
        "text_1_predicted = np.bool8(text_1_predicted)\n",
        "text_1_predicted[0,0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "   bias  bs  conspiracy  fake  hate  junksci  satire  state\n",
            "0     1   0           0     0     0        0       0      0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "df_text2_pred = pd.DataFrame(None)\n",
        "\n",
        "if text_1_predicted[0,0] == 0:\n",
        "    text_tokenised_2 = tokenizer2.texts_to_sequences([[text_news]])\n",
        "    text_tokenised_2_data = pad_sequences(text_tokenised_2, maxlen=MAX_SEQUENCE_LENGTH-1)\n",
        "    text_2_predicted = model2.predict(text_tokenised_2_data, batch_size=1024, verbose=1)\n",
        "    df_text2_pred = pd.DataFrame(text_2_predicted)\n",
        "    df_text2_pred = df_text2_pred.where(df_text2_pred!=0).rank(1, ascending=False, method='dense').eq(1).astype(int)\n",
        "    df_text2_pred.columns = label_names \n",
        "    \n",
        "print(df_text2_pred)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
